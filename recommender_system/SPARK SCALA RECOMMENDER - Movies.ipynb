{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://MSI:4041\n",
       "SparkContext available as 'sc' (version = 3.0.0, master = local[*], app id = local-1605307346616)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "import org.apache.spark.ml.evaluation.RegressionEvaluator\r\n",
       "import org.apache.spark.ml.recommendation.ALS\r\n",
       "import org.apache.spark.sql.functions._\r\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@449183c3\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "import org.apache.spark.ml.recommendation.ALS\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val spark = SparkSession.builder().appName(\"Recommender_System\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ratings: org.apache.spark.sql.DataFrame = [userId: int, movieId: int ... 1 more field]\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ratings = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(\"../../data/ml_scala/movie_ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n",
      "+-------+------------------+------------------+------------------+\n",
      "|summary|            userId|           movieId|            rating|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|  count|            100004|            100004|            100004|\n",
      "|   mean| 347.0113095476181|12548.664363425463| 3.543608255669773|\n",
      "| stddev|195.16383797819535|26369.198968815268|1.0580641091070326|\n",
      "|    min|                 1|                 1|               0.5|\n",
      "|    max|               671|            163949|               5.0|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|     31|   2.5|\n",
      "|     1|   1029|   3.0|\n",
      "|     1|   1061|   3.0|\n",
      "|     1|   1129|   2.0|\n",
      "|     1|   1172|   4.0|\n",
      "+------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.printSchema()\n",
    "ratings.describe().show()\n",
    "ratings.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userId: int, movieId: int ... 1 more field]\r\n",
       "test: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userId: int, movieId: int ... 1 more field]\r\n",
       "als: org.apache.spark.ml.recommendation.ALS = als_f0b02f9cd796\r\n",
       "model: org.apache.spark.ml.recommendation.ALSModel = ALSModel: uid=als_f0b02f9cd796, rank=10\r\n",
       "predictions: org.apache.spark.sql.DataFrame = [userId: int, movieId: int ... 2 more fields]\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create training and test datasets\n",
    "val Array(training, test) = ratings.randomSplit(Array(0.8, 0.2))\n",
    "\n",
    "// Create a new collaborative filtering model\n",
    "val als = new ALS()\n",
    "  .setMaxIter(5)\n",
    "  .setRegParam(0.01)\n",
    "  .setUserCol(\"userId\")\n",
    "  .setItemCol(\"movieId\")\n",
    "  .setRatingCol(\"rating\")\n",
    "\n",
    "//Train Model\n",
    "val model = als.fit(training)\n",
    "\n",
    "// Create Predictions\n",
    "val predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------------+\n",
      "|summary|abs((rating - prediction))|\n",
      "+-------+--------------------------+\n",
      "|  count|                     19171|\n",
      "|   mean|        0.8266293387935845|\n",
      "| stddev|        0.7143501253585149|\n",
      "|    min|       5.14984130859375E-5|\n",
      "|    max|         6.510101318359375|\n",
      "+-------+--------------------------+\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "error: org.apache.spark.sql.DataFrame = [abs((rating - prediction)): double]\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Evaluate the predictions\n",
    "val error = predictions.select(abs($\"rating\"-$\"prediction\"))\n",
    "\n",
    "error.na.drop().describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
