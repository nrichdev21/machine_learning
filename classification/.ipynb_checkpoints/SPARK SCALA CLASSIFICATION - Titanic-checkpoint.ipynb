{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "import org.apache.spark.ml.classification.LogisticRegression\r\n",
       "import org.apache.spark.ml.feature.{VectorAssembler, StringIndexer, VectorIndexer, OneHotEncoder}\r\n",
       "import org.apache.spark.ml.linalg.Vectors\r\n",
       "import org.apache.spark.ml.Pipeline\r\n",
       "import org.apache.spark.mllib.evaluation.MulticlassMetrics\r\n",
       "import org.apache.log4j._\r\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@6132a509\r\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.feature.{VectorAssembler, StringIndexer, VectorIndexer, OneHotEncoder}\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.mllib.evaluation.MulticlassMetrics\n",
    "\n",
    "import org.apache.log4j._\n",
    "Logger.getLogger(\"org\").setLevel(Level.ERROR)\n",
    "\n",
    "val spark = SparkSession.builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [PassengerId: int, Survived: int ... 10 more fields]\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = (spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\")\n",
    "          .option(\"multiline\",\"true\").format(\"csv\")\n",
    "          .load(\"../../data/ml_scala/titanic.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|summary|      PassengerId|           Survived|            Pclass|                Name|   Sex|               Age|             SibSp|              Parch|            Ticket|             Fare|Cabin|Embarked|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  204|     889|\n",
      "|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                null|  null| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| null|    null|\n",
      "| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                null|  null|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| null|    null|\n",
      "|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|              0.42|                 0|                  0|            110152|              0.0|  A10|       C|\n",
      "|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.describe().show()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Example Data Row\n",
      "Survived\n",
      "0\n",
      "\n",
      "\n",
      "Pclass\n",
      "3\n",
      "\n",
      "\n",
      "Name\n",
      "Braund, Mr. Owen Harris\n",
      "\n",
      "\n",
      "Sex\n",
      "male\n",
      "\n",
      "\n",
      "Age\n",
      "22.0\n",
      "\n",
      "\n",
      "SibSp\n",
      "1\n",
      "\n",
      "\n",
      "Parch\n",
      "0\n",
      "\n",
      "\n",
      "Ticket\n",
      "A/5 21171\n",
      "\n",
      "\n",
      "Fare\n",
      "7.25\n",
      "\n",
      "\n",
      "Cabin\n",
      "null\n",
      "\n",
      "\n",
      "Embarked\n",
      "S\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "colnames: Array[String] = Array(PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked)\r\n",
       "firstrow: org.apache.spark.sql.Row = [1,0,3,Braund, Mr. Owen Harris,male,22.0,1,0,A/5 21171,7.25,null,S]\r\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Print a row to better visualize\n",
    "val colnames = df.columns\n",
    "val firstrow = df.head(1)(0)\n",
    "println(\"\\n\")\n",
    "println(\"Example Data Row\")\n",
    "for(ind <- Range(1,colnames.length)){\n",
    "  println(colnames(ind))\n",
    "  println(firstrow(ind))\n",
    "  println(\"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+----+-----+-----+-------+--------+\n",
      "|label|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|\n",
      "+-----+------+------+----+-----+-----+-------+--------+\n",
      "|    0|     3|  male|22.0|    1|    0|   7.25|       S|\n",
      "|    1|     1|female|38.0|    1|    0|71.2833|       C|\n",
      "|    1|     3|female|26.0|    0|    0|  7.925|       S|\n",
      "|    1|     1|female|35.0|    1|    0|   53.1|       S|\n",
      "|    0|     3|  male|35.0|    0|    0|   8.05|       S|\n",
      "+-----+------+------+----+-----+-----+-------+--------+\n",
      "only showing top 5 rows\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df_detail: org.apache.spark.sql.DataFrame = [label: int, Pclass: int ... 6 more fields]\r\n",
       "df_clean: org.apache.spark.sql.DataFrame = [label: int, Pclass: int ... 6 more fields]\r\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Select relevant features and label\n",
    "val df_detail = (df.select(df(\"Survived\").as(\"label\"), $\"Pclass\",$\"Sex\",$\"Age\", $\"SibSp\",$\"Parch\"\n",
    "          ,$\"Fare\",$\"Embarked\"))\n",
    "\n",
    "// Remove rows with duplicates\n",
    "val df_clean = df_detail.na.drop()\n",
    "\n",
    "// Show dataframe\n",
    "df_clean.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genderIndexer: org.apache.spark.ml.feature.StringIndexer = strIdx_0a2e624fabd7\r\n",
       "embarkIndexer: org.apache.spark.ml.feature.StringIndexer = strIdx_43ae4971ebb1\r\n",
       "genderEncoder: org.apache.spark.ml.feature.OneHotEncoder = oneHotEncoder_9bdce6af4013\r\n",
       "embarkEncoder: org.apache.spark.ml.feature.OneHotEncoder = oneHotEncoder_cce212d6b070\r\n",
       "assembler: org.apache.spark.ml.feature.VectorAssembler = VectorAssembler: uid=vecAssembler_6cadf61c1a6a, handleInvalid=error, numInputCols=7\r\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Convert Categorical features\n",
    "val genderIndexer = new StringIndexer().setInputCol(\"Sex\").setOutputCol(\"SexIndex\")\n",
    "val embarkIndexer = new StringIndexer().setInputCol(\"Embarked\").setOutputCol(\"EmbarkIndex\")\n",
    "\n",
    "val genderEncoder = new OneHotEncoder().setInputCol(\"SexIndex\").setOutputCol(\"SexVec\")\n",
    "val embarkEncoder = new OneHotEncoder().setInputCol(\"EmbarkIndex\").setOutputCol(\"EmbarkVec\")\n",
    "\n",
    "// Create dataframe in format spark needs\n",
    "// Assemble everything together to be (\"label\",\"features\") format\n",
    "val assembler = (new VectorAssembler()\n",
    "                  .setInputCols(Array(\"Pclass\", \"SexVec\", \"Age\",\"SibSp\",\"Parch\",\"Fare\",\"EmbarkVec\"))\n",
    "                  .setOutputCol(\"features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: int, Pclass: int ... 6 more fields]\r\n",
       "test: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: int, Pclass: int ... 6 more fields]\r\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create train/test datasets\n",
    "val Array(training, test) = df_clean.randomSplit(Array(0.7,0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clf_lr: org.apache.spark.ml.classification.LogisticRegression = logreg_fffb245d5cdd\r\n",
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_78f0038338c2\r\n",
       "model: org.apache.spark.ml.PipelineModel = pipeline_78f0038338c2\r\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create classifier\n",
    "val clf_lr = new LogisticRegression()\n",
    "\n",
    "// Create pipeline\n",
    "val pipeline = new Pipeline().setStages(Array(genderIndexer,embarkIndexer,genderEncoder,\n",
    "                                              embarkEncoder,assembler, clf_lr))\n",
    "\n",
    "// Fit model\n",
    "val model = pipeline.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+----+-----+-----+--------+--------+--------+-----------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|Pclass|   Sex| Age|SibSp|Parch|    Fare|Embarked|SexIndex|EmbarkIndex|       SexVec|    EmbarkVec|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+------+------+----+-----+-----+--------+--------+--------+-----------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "|    0|     1|female| 2.0|    1|    2|  151.55|       S|     1.0|        0.0|    (1,[],[])|(2,[0],[1.0])|[1.0,0.0,2.0,1.0,...|[-4.2182401181549...|[0.01451086935212...|       1.0|\n",
      "|    0|     1|female|25.0|    1|    2|  151.55|       S|     1.0|        0.0|    (1,[],[])|(2,[0],[1.0])|[1.0,0.0,25.0,1.0...|[-3.1472194135218...|[0.04120098096572...|       1.0|\n",
      "|    0|     1|  male|21.0|    0|    1| 77.2875|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,21.0,0.0...|[-0.6610847419578...|[0.34049598142714...|       1.0|\n",
      "|    0|     1|  male|24.0|    0|    1|247.5208|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,24.0,0.0...|[-1.4689496767813...|[0.18710231041772...|       1.0|\n",
      "|    0|     1|  male|28.0|    1|    0| 82.1708|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,28.0,1.0...|[-0.2530742612640...|[0.43706696384301...|       1.0|\n",
      "+-----+------+------+----+-----+-----+--------+--------+--------+-----------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "results: org.apache.spark.sql.DataFrame = [label: int, Pclass: int ... 14 more fields]\r\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val results = model.transform(test)\n",
    "\n",
    "results.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "107.0  22.0  \n",
      "21.0   55.0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "predictionAndLabels: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[158] at rdd at <console>:67\r\n",
       "metrics: org.apache.spark.mllib.evaluation.MulticlassMetrics = org.apache.spark.mllib.evaluation.MulticlassMetrics@6e9018a9\r\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Need to convert to RDD to use Multiclass metrics class\n",
    "val predictionAndLabels = results.select($\"prediction\",$\"label\").as[(Double, Double)].rdd\n",
    "\n",
    "// Model Performance\n",
    "val metrics = new MulticlassMetrics(predictionAndLabels)\n",
    "println(\"Confusion matrix:\")\n",
    "println(metrics.confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
