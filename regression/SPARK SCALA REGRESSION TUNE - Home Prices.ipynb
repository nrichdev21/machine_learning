{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://MSI:4040\n",
       "SparkContext available as 'sc' (version = 3.0.0, master = local[*], app id = local-1605304695636)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "import org.apache.spark.ml.regression.LinearRegression\r\n",
       "import org.apache.spark.ml.evaluation.RegressionEvaluator\r\n",
       "import org.apache.spark.ml.feature.VectorAssembler\r\n",
       "import org.apache.spark.ml.linalg.Vectors\r\n",
       "import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}\r\n",
       "import org.apache.log4j._\r\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@57b6eb4b\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.ml.regression.LinearRegression\n",
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "\n",
    "import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}\n",
    "\n",
    "import org.apache.log4j._\n",
    "Logger.getLogger(\"org\").setLevel(Level.ERROR)\n",
    "\n",
    "val spark = SparkSession.builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_house: org.apache.spark.sql.DataFrame = [Avg Area Income: double, Avg Area House Age: double ... 5 more fields]\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_house = (spark.read.option(\"header\",\"true\").option(\"multiline\",\"true\").option(\"inferSchema\",\"true\").format(\"csv\")\n",
    "          .load(\"../../data/ml_scala/USA_Housing.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Avg Area Income: double (nullable = true)\n",
      " |-- Avg Area House Age: double (nullable = true)\n",
      " |-- Avg Area Number of Rooms: double (nullable = true)\n",
      " |-- Avg Area Number of Bedrooms: double (nullable = true)\n",
      " |-- Area Population: double (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      "\n",
      "+-------+------------------+------------------+------------------------+---------------------------+------------------+------------------+--------------------+\n",
      "|summary|   Avg Area Income|Avg Area House Age|Avg Area Number of Rooms|Avg Area Number of Bedrooms|   Area Population|             Price|             Address|\n",
      "+-------+------------------+------------------+------------------------+---------------------------+------------------+------------------+--------------------+\n",
      "|  count|              5000|              5000|                    5000|                       5000|              5000|              5000|                5000|\n",
      "|   mean| 68583.10898395971|  5.97722203528029|       6.987791850907942|         3.9813299999999967| 36163.51603857463|  1232072.65414236|                null|\n",
      "| stddev|10657.991213830363|0.9914561798281722|      1.0058332312773866|         1.2341372654846832| 9925.650113501246|353117.62658106035|                null|\n",
      "|    min|17796.631189543397| 2.644304186036705|      3.2361940234262048|                        2.0|172.61068627290044|15938.657923287848|000 Adkins Cresce...|\n",
      "|    max|107701.74837763935|  9.51908806613594|      10.759588335938624|                        6.5|  69621.7133777904|2469065.5941747027|Unit 9871 Box 903...|\n",
      "+-------+------------------+------------------+------------------------+---------------------------+------------------+------------------+--------------------+\n",
      "\n",
      "+------------------+------------------+------------------------+---------------------------+------------------+------------------+--------------------+\n",
      "|   Avg Area Income|Avg Area House Age|Avg Area Number of Rooms|Avg Area Number of Bedrooms|   Area Population|             Price|             Address|\n",
      "+------------------+------------------+------------------------+---------------------------+------------------+------------------+--------------------+\n",
      "| 79545.45857431678| 5.682861321615587|       7.009188142792237|                       4.09|23086.800502686456|1059033.5578701235|208 Michael Ferry...|\n",
      "| 79248.64245482568|6.0028998082752425|       6.730821019094919|                       3.09| 40173.07217364482|  1505890.91484695|188 Johnson Views...|\n",
      "|61287.067178656784| 5.865889840310001|       8.512727430375099|                       5.13| 36882.15939970458|1058987.9878760849|9127 Elizabeth St...|\n",
      "| 63345.24004622798|7.1882360945186425|       5.586728664827653|                       3.26| 34310.24283090706|1260616.8066294468|USS Barnett\n",
      "FPO A...|\n",
      "|59982.197225708034| 5.040554523106283|       7.839387785120487|                       4.23|26354.109472103148| 630943.4893385402|USNS Raymond\n",
      "FPO ...|\n",
      "+------------------+------------------+------------------------+---------------------------+------------------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_house.printSchema()\n",
    "df_house.describe().show()\n",
    "df_house.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Example Data Row\n",
      "Avg Area House Age\n",
      "5.682861321615587\n",
      "\n",
      "\n",
      "Avg Area Number of Rooms\n",
      "7.009188142792237\n",
      "\n",
      "\n",
      "Avg Area Number of Bedrooms\n",
      "4.09\n",
      "\n",
      "\n",
      "Area Population\n",
      "23086.800502686456\n",
      "\n",
      "\n",
      "Price\n",
      "1059033.5578701235\n",
      "\n",
      "\n",
      "Address\n",
      "208 Michael Ferry Apt. 674\n",
      "Laurabury, NE 37010-5101\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "colnames: Array[String] = Array(Avg Area Income, Avg Area House Age, Avg Area Number of Rooms, Avg Area Number of Bedrooms, Area Population, Price, Address)\r\n",
       "firstrow: org.apache.spark.sql.Row =\r\n",
       "[79545.45857431678,5.682861321615587,7.009188142792237,4.09,23086.800502686456,1059033.5578701235,208 Michael Ferry Apt. 674\r\n",
       "Laurabury, NE 37010-5101]\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Better visualization on what a record looks like\n",
    "val colnames = df_house.columns\n",
    "val firstrow = df_house.head(1)(0)\n",
    "println(\"\\n\")\n",
    "println(\"Example Data Row\")\n",
    "for(ind <- Range(1,colnames.length)){\n",
    "  println(colnames(ind))\n",
    "  println(firstrow(ind))\n",
    "  println(\"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+\n",
      "|             label|            features|\n",
      "+------------------+--------------------+\n",
      "|1059033.5578701235|[79545.4585743167...|\n",
      "|  1505890.91484695|[79248.6424548256...|\n",
      "|1058987.9878760849|[61287.0671786567...|\n",
      "|1260616.8066294468|[63345.2400462279...|\n",
      "| 630943.4893385402|[59982.1972257080...|\n",
      "+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [label: double, Avg Area Income: double ... 4 more fields]\r\n",
       "assembler: org.apache.spark.ml.feature.VectorAssembler = VectorAssembler: uid=vecAssembler_f6e9234bc1cb, handleInvalid=error, numInputCols=5\r\n",
       "output: org.apache.spark.sql.DataFrame = [label: double, features: vector]\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Prep dataframe to include features and label matrix\n",
    "val df = (df_house.select(df_house(\"Price\").as(\"label\"),\n",
    "                            $\"Avg Area Income\", $\"Avg Area House Age\", $\"Avg Area Number of Rooms\",\n",
    "                            $\"Avg Area Number of Bedrooms\", $\"Area Population\"))\n",
    "\n",
    "val assembler = (new VectorAssembler()\n",
    "                 .setInputCols(Array(\"Avg Area Income\", \"Avg Area House Age\",\n",
    "                                    \"Avg Area Number of Rooms\", \"Avg Area Number of Bedrooms\",\n",
    "                                    \"Area Population\")).setOutputCol(\"features\"))\n",
    "\n",
    "val output = assembler.transform(df).select($\"label\",$\"features\")\n",
    "\n",
    "output.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: double, features: vector]\r\n",
       "test: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: double, features: vector]\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Train test split\n",
    "val Array(training, test) = output.select(\"label\",\"features\").randomSplit(Array(0.8,0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------------+\n",
      "|            features|             label|        prediction|\n",
      "+--------------------+------------------+------------------+\n",
      "|[60167.6726073388...| 88591.77016003926|158079.80872222036|\n",
      "|[48735.9245124086...| 151527.0826265551| 368883.0853910432|\n",
      "|[47685.2575946853...|  294170.746352692|249798.80601892946|\n",
      "|[49601.0616347867...| 302307.4010604978|367703.17610806273|\n",
      "|[17796.6311895433...|302355.83597895555| 92036.40603054548|\n",
      "|[59141.7964422585...| 313651.5032332925| 526641.9332406619|\n",
      "|[47018.0671117179...|377618.96990141843|438257.60227354383|\n",
      "|[51218.6782600275...| 385678.1666731234|393547.35729224375|\n",
      "|[48829.1727051231...|412057.44010888686| 385186.5530622406|\n",
      "|[66469.3694730564...| 412269.2033995612| 658565.0222779778|\n",
      "|[48510.9101270763...|414165.22036082624|523686.46361347754|\n",
      "|[58198.0323119737...|420122.99953232025| 245132.2733218181|\n",
      "|[63787.5363538975...|433247.15658337076| 578652.7563742837|\n",
      "|[46800.3725884912...|  456019.171216889| 557905.5659523215|\n",
      "|[51621.3304207314...| 459446.4192774692| 321071.8341060183|\n",
      "|[62635.2599238025...| 461912.2442841672| 607676.3684573895|\n",
      "|[54259.4760522204...|469016.24780787673| 609531.6765492251|\n",
      "|[64536.0149817613...|491907.79437121906| 627463.2539705653|\n",
      "|[45750.4935831081...|494609.03343102656| 519120.0112191108|\n",
      "|[40581.778087153,...|  509499.588996669| 571968.5674688625|\n",
      "+--------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lr: org.apache.spark.ml.regression.LinearRegression = linReg_66d61659e810\r\n",
       "paramGrid: Array[org.apache.spark.ml.param.ParamMap] =\r\n",
       "Array({\r\n",
       "\tlinReg_66d61659e810-elasticNetParam: 0.0,\r\n",
       "\tlinReg_66d61659e810-fitIntercept: true,\r\n",
       "\tlinReg_66d61659e810-regParam: 0.1\r\n",
       "}, {\r\n",
       "\tlinReg_66d61659e810-elasticNetParam: 0.0,\r\n",
       "\tlinReg_66d61659e810-fitIntercept: true,\r\n",
       "\tlinReg_66d61659e810-regParam: 0.01\r\n",
       "}, {\r\n",
       "\tlinReg_66d61659e810-elasticNetParam: 0.0,\r\n",
       "\tlinReg_66d61659e810-fitIntercept: false,\r\n",
       "\tlinReg_66d61659e810-regParam: 0.1\r\n",
       "}, {\r\n",
       "\tlinReg_66d61659e810-elasticNetParam: 0.0,\r\n",
       "\tlinReg_66d61659e810-fitIntercept: false,\r\n",
       "\tlinReg_66d61659e810-regParam: 0.01\r\n",
       "}, {\r\n",
       "\tlinReg_66d61659e810-elasticNetParam: 0.5,\r\n",
       "\tlinReg_66d61659e810-fitIntercept: true,\r\n",
       "\tlinReg_66d61659e810-regParam: 0.1\r\n",
       "}, {\r\n",
       "\tlinReg_66d61...\r\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create basic regression model\n",
    "val lr = new LinearRegression()\n",
    "\n",
    "// Create hyper-paramter grid for tuning\n",
    "val paramGrid = (new ParamGridBuilder().addGrid(lr.regParam, Array(0.1,0.01))\n",
    "                 .addGrid(lr.fitIntercept).addGrid(lr.elasticNetParam, Array(0.0,0.5,0.01))\n",
    "                 .build())\n",
    "\n",
    "// Validation for hyperparameter tuning - similiar to CV but only trains once\n",
    "val trainValidationSplit = (new TrainValidationSplit()\n",
    "                            .setEstimator(lr)\n",
    "                            .setEvaluator(new RegressionEvaluator().setMetricName(\"r2\") )\n",
    "                            .setEstimatorParamMaps(paramGrid)\n",
    "                            .setTrainRatio(0.8) )\n",
    "\n",
    "//  Train the model\n",
    "val model = trainValidationSplit.fit(training)\n",
    "\n",
    "// Show predictions against test labels\n",
    "model.transform(test).select(\"features\", \"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res4: Array[Double] = Array(0.9184783661169755, 0.9184783711250816, 0.49917048882672466, 0.4991704770823169, 0.9184783625794555, 0.9184783706577778, 0.4963969247843364, 0.4969666689739859, 0.9184783660802863, 0.9184783712342668, 0.4969666761192497, 0.49696666531763534)\r\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Model Performance\n",
    "model.validationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prod_model: org.apache.spark.ml.Model[_] = LinearRegressionModel: uid=linReg_66d61659e810, numFeatures=5\r\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val prod_model = model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
